{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, \\\n",
    "                        allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.distributions as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computes the KL divergence D_KL(P||Q) between the distributions of P and Q, \n",
    "# given an equal number of samples drawn from them\n",
    "def KL_network(data_P, data_Q, name):\n",
    "    with tf.variable_scope(name):  \n",
    "        data_combined = tf.concat([data_P, data_Q], axis = 0)\n",
    "        \n",
    "        lay = layers.relu(data_combined, 20)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 1)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = name)\n",
    "    \n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KL_loss(KL_output, name):\n",
    "    with tf.variable_scope(name):\n",
    "        batch_size_dyn = tf.cast(tf.math.divide(tf.shape(KL_output)[0], 2), tf.int32)\n",
    "        \n",
    "        T_P = KL_output[:batch_size_dyn,:]\n",
    "        T_Q = KL_output[batch_size_dyn:,:]\n",
    "        \n",
    "        TF_loss = -(tf.reduce_mean(T_P, axis = 0) - tf.math.log(tf.reduce_mean(tf.math.exp(T_Q), axis = 0)))\n",
    "        \n",
    "        TF_loss = TF_loss[0]\n",
    "        \n",
    "    return TF_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model_params'):\n",
    "    mu = tf.Variable(2.0, 'mu')\n",
    "    sigma = tf.Variable(3.0, 'sigma')\n",
    "\n",
    "model_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'model_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ds.Normal(loc = mu, scale = sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_model = model.sample((50000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_in = tf.placeholder(tf.float32, [None, 1], name = 'data_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KL_output, KL_vars = KL_network(data_in, samples_model, name = 'KL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KL_lossval = KL_loss(KL_output, 'KL_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_KL = tf.train.AdamOptimizer(learning_rate = 0.005, beta1 = 0.3, beta2 = 0.5).minimize(KL_lossval, var_list = KL_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_model = tf.train.AdamOptimizer(learning_rate = 0.05, beta1 = 0.9, beta2 = 0.999).minimize(-KL_lossval, var_list = model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = np.random.normal(loc = 0, scale = 1, size = 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = np.expand_dims(data_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in range(50):\n",
    "    sess.run(train_KL, feed_dict = {data_in: data_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss = 0.8681875467300415\n",
      "mu = 1.9500000476837158, sigma = 2.950000047683716\n",
      "epoch 1: loss = 0.8681941628456116\n",
      "mu = 1.900011420249939, sigma = 2.899944305419922\n",
      "epoch 2: loss = 0.8428404331207275\n",
      "mu = 1.8499565124511719, sigma = 2.8499794006347656\n",
      "epoch 3: loss = 0.8198143243789673\n",
      "mu = 1.8000038862228394, sigma = 2.799805164337158\n",
      "epoch 4: loss = 0.7981064319610596\n",
      "mu = 1.7500636577606201, sigma = 2.7494826316833496\n",
      "epoch 5: loss = 0.7763665318489075\n",
      "mu = 1.7000980377197266, sigma = 2.699099540710449\n",
      "epoch 6: loss = 0.7622635960578918\n",
      "mu = 1.650078296661377, sigma = 2.6485257148742676\n",
      "epoch 7: loss = 0.7402007579803467\n",
      "mu = 1.599927544593811, sigma = 2.5979161262512207\n",
      "epoch 8: loss = 0.716325044631958\n",
      "mu = 1.5497430562973022, sigma = 2.5470669269561768\n",
      "epoch 9: loss = 0.6947574019432068\n",
      "mu = 1.4993613958358765, sigma = 2.496091365814209\n",
      "epoch 10: loss = 0.6784394383430481\n",
      "mu = 1.448998212814331, sigma = 2.4448530673980713\n",
      "epoch 11: loss = 0.6449662446975708\n",
      "mu = 1.3984163999557495, sigma = 2.393608808517456\n",
      "epoch 12: loss = 0.640572190284729\n",
      "mu = 1.3479236364364624, sigma = 2.3419687747955322\n",
      "epoch 13: loss = 0.6073457598686218\n",
      "mu = 1.297295331954956, sigma = 2.290140151977539\n",
      "epoch 14: loss = 0.5868152379989624\n",
      "mu = 1.2465935945510864, sigma = 2.237971544265747\n",
      "epoch 15: loss = 0.558287501335144\n",
      "mu = 1.1958932876586914, sigma = 2.1855151653289795\n",
      "epoch 16: loss = 0.5339165925979614\n",
      "mu = 1.145110011100769, sigma = 2.132781982421875\n",
      "epoch 17: loss = 0.5089893341064453\n",
      "mu = 1.0943467617034912, sigma = 2.079617977142334\n",
      "epoch 18: loss = 0.4794016480445862\n",
      "mu = 1.0433175563812256, sigma = 2.0262763500213623\n",
      "epoch 19: loss = 0.4634709358215332\n",
      "mu = 0.9922726154327393, sigma = 1.9725096225738525\n",
      "epoch 20: loss = 0.43154752254486084\n",
      "mu = 0.9411240816116333, sigma = 1.9184380769729614\n",
      "epoch 21: loss = 0.4105045795440674\n",
      "mu = 0.8900356888771057, sigma = 1.8639132976531982\n",
      "epoch 22: loss = 0.378120094537735\n",
      "mu = 0.838790237903595, sigma = 1.809108853340149\n",
      "epoch 23: loss = 0.351637065410614\n",
      "mu = 0.787507176399231, sigma = 1.7539440393447876\n",
      "epoch 24: loss = 0.3315870761871338\n",
      "mu = 0.7362111210823059, sigma = 1.698461651802063\n",
      "epoch 25: loss = 0.2937581241130829\n",
      "mu = 0.6847487092018127, sigma = 1.6427901983261108\n",
      "epoch 26: loss = 0.2659650146961212\n",
      "mu = 0.6336904764175415, sigma = 1.586557149887085\n",
      "epoch 27: loss = 0.23681768774986267\n",
      "mu = 0.5825967788696289, sigma = 1.5300660133361816\n",
      "epoch 28: loss = 0.21158918738365173\n",
      "mu = 0.5313912630081177, sigma = 1.473447561264038\n",
      "epoch 29: loss = 0.1889668107032776\n",
      "mu = 0.48048925399780273, sigma = 1.4166679382324219\n",
      "epoch 30: loss = 0.15855136513710022\n",
      "mu = 0.4295850396156311, sigma = 1.3599698543548584\n",
      "epoch 31: loss = 0.13010519742965698\n",
      "mu = 0.3791047930717468, sigma = 1.303354263305664\n",
      "epoch 32: loss = 0.10156577825546265\n",
      "mu = 0.3289763331413269, sigma = 1.2472264766693115\n",
      "epoch 33: loss = 0.07634198665618896\n",
      "mu = 0.2795073390007019, sigma = 1.1917604207992554\n",
      "epoch 34: loss = 0.056802898645401\n",
      "mu = 0.23082180321216583, sigma = 1.1371650695800781\n",
      "epoch 35: loss = 0.03528258204460144\n",
      "mu = 0.18304160237312317, sigma = 1.0840928554534912\n",
      "epoch 36: loss = 0.020734846591949463\n",
      "mu = 0.13656115531921387, sigma = 1.0334194898605347\n",
      "epoch 37: loss = 0.009332150220870972\n",
      "mu = 0.09214609861373901, sigma = 0.9860787391662598\n",
      "epoch 38: loss = 0.0022873282432556152\n",
      "mu = 0.050062358379364014, sigma = 0.9432874321937561\n",
      "epoch 39: loss = 0.0018039345741271973\n",
      "mu = 0.01127670705318451, sigma = 0.9063440561294556\n",
      "epoch 40: loss = 0.006449103355407715\n",
      "mu = -0.023737840354442596, sigma = 0.8769218921661377\n",
      "epoch 41: loss = 0.014445841312408447\n",
      "mu = -0.05460071563720703, sigma = 0.8564984798431396\n",
      "epoch 42: loss = 0.019100308418273926\n",
      "mu = -0.08040665090084076, sigma = 0.8462636470794678\n",
      "epoch 43: loss = 0.030388474464416504\n",
      "mu = -0.10112163424491882, sigma = 0.8462167382240295\n",
      "epoch 44: loss = 0.030879318714141846\n",
      "mu = -0.11580047011375427, sigma = 0.8560475707054138\n",
      "epoch 45: loss = 0.030013740062713623\n",
      "mu = -0.1261645257472992, sigma = 0.8734363913536072\n",
      "epoch 46: loss = 0.025326251983642578\n",
      "mu = -0.13280603289604187, sigma = 0.8962876796722412\n",
      "epoch 47: loss = 0.018561899662017822\n",
      "mu = -0.13570304214954376, sigma = 0.9230169653892517\n",
      "epoch 48: loss = 0.013393104076385498\n",
      "mu = -0.13566678762435913, sigma = 0.9516187906265259\n",
      "epoch 49: loss = 0.011600792407989502\n",
      "mu = -0.13308608531951904, sigma = 0.9805349707603455\n",
      "epoch 50: loss = 0.007317781448364258\n",
      "mu = -0.1286621242761612, sigma = 1.0081205368041992\n",
      "epoch 51: loss = 0.006707429885864258\n",
      "mu = -0.12238263338804245, sigma = 1.0334477424621582\n",
      "epoch 52: loss = 0.0065059661865234375\n",
      "mu = -0.11457361280918121, sigma = 1.0555293560028076\n",
      "epoch 53: loss = 0.006918579339981079\n",
      "mu = -0.10599327087402344, sigma = 1.0732927322387695\n",
      "epoch 54: loss = 0.008586078882217407\n",
      "mu = -0.09548526257276535, sigma = 1.0873762369155884\n",
      "epoch 55: loss = 0.008898705244064331\n",
      "mu = -0.08437430113554001, sigma = 1.0971710681915283\n",
      "epoch 56: loss = 0.009272545576095581\n",
      "mu = -0.07313305139541626, sigma = 1.1024924516677856\n",
      "epoch 57: loss = 0.010877728462219238\n",
      "mu = -0.061184585094451904, sigma = 1.103774905204773\n",
      "epoch 58: loss = 0.011667817831039429\n",
      "mu = -0.049622297286987305, sigma = 1.1011321544647217\n",
      "epoch 59: loss = 0.00998985767364502\n",
      "mu = -0.03801299259066582, sigma = 1.0954054594039917\n",
      "epoch 60: loss = 0.007906675338745117\n",
      "mu = -0.027459092438220978, sigma = 1.0865968465805054\n",
      "epoch 61: loss = 0.006718248128890991\n",
      "mu = -0.01688586361706257, sigma = 1.0754436254501343\n",
      "epoch 62: loss = 0.0046409666538238525\n",
      "mu = -0.007397647015750408, sigma = 1.0622258186340332\n",
      "epoch 63: loss = 0.0035619139671325684\n",
      "mu = 0.0013122418895363808, sigma = 1.0479182004928589\n",
      "epoch 64: loss = 0.0019126534461975098\n",
      "mu = 0.008661996573209763, sigma = 1.0331051349639893\n",
      "epoch 65: loss = 0.0006604194641113281\n",
      "mu = 0.014693399891257286, sigma = 1.018486499786377\n",
      "epoch 66: loss = -0.00023049116134643555\n",
      "mu = 0.02016410045325756, sigma = 1.0051316022872925\n",
      "epoch 67: loss = -0.00040787458419799805\n",
      "mu = 0.023363914340734482, sigma = 0.9928132891654968\n",
      "epoch 68: loss = -0.00012928247451782227\n",
      "mu = 0.026149990037083626, sigma = 0.9818140864372253\n",
      "epoch 69: loss = 0.00023180246353149414\n",
      "mu = 0.028563685715198517, sigma = 0.9725717306137085\n",
      "epoch 70: loss = 0.000728309154510498\n",
      "mu = 0.028881151229143143, sigma = 0.9648479223251343\n",
      "epoch 71: loss = 0.001156628131866455\n",
      "mu = 0.028261039406061172, sigma = 0.9594939947128296\n",
      "epoch 72: loss = 0.0018061399459838867\n",
      "mu = 0.02750975452363491, sigma = 0.9571613669395447\n",
      "epoch 73: loss = 0.0019019246101379395\n",
      "mu = 0.0249168798327446, sigma = 0.9572349786758423\n",
      "epoch 74: loss = 0.0018959641456604004\n",
      "mu = 0.021898195147514343, sigma = 0.9593656063079834\n",
      "epoch 75: loss = 0.0019834041595458984\n",
      "mu = 0.018391745164990425, sigma = 0.963227391242981\n",
      "epoch 76: loss = 0.0017644762992858887\n",
      "mu = 0.014292750507593155, sigma = 0.9682367444038391\n",
      "epoch 77: loss = 0.00012296438217163086\n",
      "mu = 0.011339477263391018, sigma = 0.9746754169464111\n",
      "epoch 78: loss = 0.00048297643661499023\n",
      "mu = 0.007479881402105093, sigma = 0.9815660119056702\n",
      "epoch 79: loss = 0.00014632940292358398\n",
      "mu = 0.003314390778541565, sigma = 0.9884058833122253\n",
      "epoch 80: loss = -0.00019371509552001953\n",
      "mu = 0.00011156057007610798, sigma = 0.9951420426368713\n",
      "epoch 81: loss = -1.430511474609375e-06\n",
      "mu = -0.003525296924635768, sigma = 1.0013537406921387\n",
      "epoch 82: loss = -0.0002993345260620117\n",
      "mu = -0.006415612995624542, sigma = 1.0072598457336426\n",
      "epoch 83: loss = -0.00025385618209838867\n",
      "mu = -0.009161697700619698, sigma = 1.0116969347000122\n",
      "epoch 84: loss = -2.7358531951904297e-05\n",
      "mu = -0.011318831704556942, sigma = 1.0146929025650024\n",
      "epoch 85: loss = 1.7583370208740234e-05\n",
      "mu = -0.01233462244272232, sigma = 1.0164430141448975\n",
      "epoch 86: loss = -0.0005622506141662598\n",
      "mu = -0.014232703484594822, sigma = 1.0166373252868652\n",
      "epoch 87: loss = 0.00041747093200683594\n",
      "mu = -0.015506697818636894, sigma = 1.0159900188446045\n",
      "epoch 88: loss = 0.00033283233642578125\n",
      "mu = -0.01649317890405655, sigma = 1.0145827531814575\n",
      "epoch 89: loss = -0.0002822279930114746\n",
      "mu = -0.016362298280000687, sigma = 1.0125007629394531\n",
      "epoch 90: loss = -2.276897430419922e-05\n",
      "mu = -0.01680659130215645, sigma = 1.009369134902954\n",
      "epoch 91: loss = -8.749961853027344e-05\n",
      "mu = -0.016045184805989265, sigma = 1.006126046180725\n",
      "epoch 92: loss = 0.00021642446517944336\n",
      "mu = -0.0149980578571558, sigma = 1.0029159784317017\n",
      "epoch 93: loss = -9.000301361083984e-05\n",
      "mu = -0.014077933505177498, sigma = 1.0001764297485352\n",
      "epoch 94: loss = -0.00016367435455322266\n",
      "mu = -0.012643998488783836, sigma = 0.9978641867637634\n",
      "epoch 95: loss = -0.00039637088775634766\n",
      "mu = -0.012055758386850357, sigma = 0.9953466653823853\n",
      "epoch 96: loss = -0.00020307302474975586\n",
      "mu = -0.010493121109902859, sigma = 0.99331134557724\n",
      "epoch 97: loss = -0.00010401010513305664\n",
      "mu = -0.009559933096170425, sigma = 0.9915250539779663\n",
      "epoch 98: loss = 3.0517578125e-05\n",
      "mu = -0.008285513147711754, sigma = 0.9905104041099548\n",
      "epoch 99: loss = -1.436471939086914e-05\n",
      "mu = -0.007071726024150848, sigma = 0.9905192852020264\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):      \n",
    "    sess.run(train_KL, feed_dict = {data_in: data_train})\n",
    "    cur_KL = -sess.run(KL_lossval, feed_dict = {data_in: data_train})\n",
    "    \n",
    "    sess.run(train_model, feed_dict = {data_in: data_train})\n",
    "    \n",
    "    cur_mu = sess.run(mu)\n",
    "    cur_sigma = sess.run(sigma)\n",
    "    \n",
    "    print(\"epoch {}: loss = {}\".format(epoch, cur_KL))\n",
    "    print(\"mu = {}, sigma = {}\".format(cur_mu, cur_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
