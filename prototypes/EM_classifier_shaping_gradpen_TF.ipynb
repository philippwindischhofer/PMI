{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.mlab import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.layers as layers\n",
    "import tensorflow.contrib.distributions as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, \\\n",
    "                        allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(n_samples):\n",
    "    data = []\n",
    "    labels = []\n",
    "    nuisances = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        sig_bkg = np.random.uniform(low = 0.0, high = 1.0, size = 1)\n",
    "        if sig_bkg > 0.5:\n",
    "            nuisance = np.random.uniform(low = 0.0, high = 2.0, size = 1)\n",
    "            data.append(np.random.multivariate_normal(mean = [0.0, nuisance], cov = np.array([[1, -0.5], [-0.5, 1]]), size = 1).flatten())\n",
    "            labels.append(1.0)\n",
    "        else:\n",
    "            nuisance = np.random.uniform(low = 0.0, high = 2.0, size = 1)\n",
    "            data.append(np.random.multivariate_normal(mean = [1.0, nuisance], cov = np.eye(2), size = 1).flatten())\n",
    "            labels.append(0.0)\n",
    "            \n",
    "        nuisances.append(nuisance)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    nuisances = np.array(nuisances)\n",
    "    \n",
    "    return data, labels, nuisances.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "data_train, labels_train, nuisances_train = prepare_data(num_samples)\n",
    "nuisances_train = np.expand_dims(nuisances_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_in = tf.placeholder(tf.float32, [None, 2], name = 'data_in')\n",
    "nuisances_in = tf.placeholder(tf.float32, [None, 1], name = 'nuisances_in')\n",
    "labels_in = tf.placeholder(tf.int32, [None, ], name = 'labels_in')\n",
    "noise_in = tf.placeholder(tf.float32, [None, 2], name = 'noise_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier(classifier_input, random_input):\n",
    "    with tf.variable_scope(\"classifier\"):\n",
    "        #lay = tf.concat([classifier_input, random_input], axis = 1)\n",
    "        lay = layers.relu(random_input, 50)\n",
    "        lay = layers.relu(lay, 50)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        lay = layers.relu(lay, 2)\n",
    "        outputs = layers.softmax(lay)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"classifier\")\n",
    "\n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_network(data, name, reuse = tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(name, reuse = reuse):       \n",
    "        lay = layers.relu(data, 40)\n",
    "        lay = layers.relu(lay, 40)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 1)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = name)\n",
    "    \n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_loss(data_P, data_Q, name):\n",
    "    local_EM_network_name = name + \"_EM_net\"\n",
    "    \n",
    "    T_P, EM_vars = EM_network(data_P, name = local_EM_network_name)\n",
    "    T_Q, _ = EM_network(data_Q, name = local_EM_network_name)\n",
    "\n",
    "    EM_loss = tf.reduce_mean(T_P, axis = 0) - tf.reduce_mean(T_Q, axis = 0)\n",
    "    \n",
    "    batch_size_dyn = tf.cast(tf.shape(T_P)[0], tf.int32)\n",
    "    rand = tf.random.uniform(shape = (batch_size_dyn, 1), minval = 0.0, maxval = 1.0)\n",
    "    \n",
    "    # add gradient penalty\n",
    "    x_grad = tf.math.add(tf.math.multiply(rand, data_P),\n",
    "                         tf.math.multiply(tf.math.subtract(1.0, rand), data_Q))\n",
    "    x_grad_EM, _ = EM_network(x_grad, name = local_EM_network_name)\n",
    "    grad = tf.gradients(x_grad_EM, x_grad)[0]\n",
    "    \n",
    "    grad_pen = tf.reduce_mean(tf.square(tf.math.abs(grad) - 1.0), axis = 0)[0]\n",
    "\n",
    "    EM_loss_grad_pen = EM_loss[0] + 10 * grad_pen\n",
    "\n",
    "    return EM_loss_grad_pen, EM_vars, EM_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model_params'):\n",
    "    low = tf.Variable(0.3, 'low')\n",
    "    high = tf.Variable(0.03, 'high')\n",
    "\n",
    "model_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'model_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_output, classifier_vars = classifier(data_in, noise_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_output_expanded = tf.expand_dims(classifier_output[:,0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bkg_indices = tf.where(tf.math.less(labels_in, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_bkg_input_samples = tf.gather_nd(data_in, bkg_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_bkg_samples = tf.gather_nd(classifier_output_expanded, bkg_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ds.Normal(loc = low, scale = high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#batch_size_dyn = tf.cast(tf.shape(classifier_bkg_samples)[0], tf.int32)\n",
    "samples_model = model.sample((5000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EM_lossval, EM_vars, critic = EM_loss(samples_model, classifier_output_expanded, 'EM_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_one_hot = tf.one_hot(labels_in, depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_loss = tf.losses.softmax_cross_entropy(onehot_labels = labels_one_hot, logits = classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EM_regularized_loss = 10 * tf.math.square(critic) #classification_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_regularized_classifier = tf.train.AdamOptimizer(learning_rate = 0.005, beta1 = 0.0, beta2 = 0.9).minimize(EM_regularized_loss, var_list = classifier_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb72b8647a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_EM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEM_lossval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "train_EM = tf.train.AdamOptimizer(learning_rate = 0.005, beta1 = 0.9, beta2 = 0.999).minimize(EM_lossval, var_list = EM_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined training\n",
    "classification_loss_evolution = []\n",
    "MI_evolution = []\n",
    "number_batches = 200\n",
    "MINE_batches = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bkg = labels_train == 0\n",
    "bkg_data_train = data_train[train_bkg]\n",
    "bkg_labels_train = labels_train[train_bkg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sig = labels_train == 1\n",
    "sig_data_train = data_train[train_sig]\n",
    "sig_labels_train = labels_train[train_sig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_EM = tf.variables_initializer(var_list = EM_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init_EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM = [0.01991475]\n",
      "EM = [0.02873889]\n",
      "EM = [0.02897778]\n",
      "EM = [0.02995726]\n",
      "EM = [0.03145203]\n",
      "EM = [0.02846572]\n",
      "EM = [0.02944851]\n",
      "EM = [0.02947399]\n",
      "EM = [0.02930182]\n",
      "EM = [0.02982208]\n"
     ]
    }
   ],
   "source": [
    "# pre-train EM\n",
    "for batch in range(2000):\n",
    "    inds = np.random.choice(len(bkg_data_train), 5000)\n",
    "    bkg_batch_data = bkg_data_train[inds]\n",
    "    bkg_batch_labels = bkg_labels_train[inds]\n",
    "    noise_batch = np.random.uniform(low = 0.0, high = 1.0, size = (5000, 2))\n",
    "    \n",
    "    #a_cur, b_cur = sess.run([classifier_bkg_samples, samples_model], feed_dict = {data_in: bkg_batch_data, labels_in: bkg_batch_labels})\n",
    "    #a.append(a_cur)\n",
    "    #b.append(b_cur)\n",
    "    \n",
    "    sess.run([train_EM], feed_dict = {data_in: bkg_batch_data, labels_in: bkg_batch_labels, noise_in: noise_batch})\n",
    "    \n",
    "    if not batch % 200:\n",
    "        cur_EM = sess.run(critic, feed_dict = {data_in: bkg_batch_data, labels_in: bkg_batch_labels, noise_in: noise_batch})\n",
    "        print(\"EM = {}\".format(cur_EM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critic after pre-training = [-0.20149115]\n"
     ]
    }
   ],
   "source": [
    "cur_EM = sess.run(critic, feed_dict = {data_in: bkg_batch_data, labels_in: bkg_batch_labels, noise_in: noise_batch})\n",
    "print(\"critic after pre-training = {}\".format(cur_EM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "class_loss = 0.9265249967575073, critic = [-0.01098806], tot = [0.00088103]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(\"epoch {}\".format(epoch))\n",
    "    \n",
    "    for batch in range(1):\n",
    "        \n",
    "        # update EM\n",
    "        for i in range(2000):\n",
    "            inds = np.random.choice(len(bkg_data_train), 5000)\n",
    "            bkg_batch_data = bkg_data_train[inds]\n",
    "            bkg_batch_labels = bkg_labels_train[inds]\n",
    "            noise_batch = np.random.uniform(low = 0.0, high = 1.0, size = (5000, 2))\n",
    "    \n",
    "            sess.run([train_EM], feed_dict = {data_in: bkg_batch_data, labels_in: bkg_batch_labels, noise_in: noise_batch})      \n",
    "    \n",
    "        # train regularized classifier on sig + bkg\n",
    "        inds_bkg = np.random.choice(len(bkg_data_train), 5000)\n",
    "        bkg_batch_data = bkg_data_train[inds_bkg]\n",
    "        bkg_batch_labels = bkg_labels_train[inds_bkg]\n",
    "        noise_batch = np.random.uniform(low = 0.0, high = 1.0, size = (5000, 2))\n",
    "\n",
    "        #inds_sig = np.random.choice(len(sig_data_train), 5000)\n",
    "        #sig_batch_data = sig_data_train[inds_sig]\n",
    "        #sig_batch_labels = sig_labels_train[inds_sig]\n",
    "\n",
    "        #data_batch = np.concatenate([sig_batch_data, bkg_batch_data])\n",
    "        #labels_batch = np.concatenate([sig_batch_labels, bkg_batch_labels])\n",
    "        \n",
    "        data_batch = bkg_batch_data\n",
    "        labels_batch = bkg_batch_labels\n",
    "        \n",
    "        #critic_val = sess.run(critic, feed_dict = {data_in: data_batch, labels_in: labels_batch})\n",
    "        #print(\"critic before training classifier = {}\".format(critic_val))\n",
    "        \n",
    "        sess.run(train_regularized_classifier, feed_dict = {data_in: data_batch, labels_in: labels_batch, noise_in: noise_batch})\n",
    "                \n",
    "        if not batch % 1:\n",
    "            critic_val = sess.run(critic, feed_dict = {data_in: data_batch, labels_in: labels_batch, noise_in: noise_batch})\n",
    "            class_loss = sess.run(classification_loss, feed_dict = {data_in: data_batch, labels_in: labels_batch, noise_in: noise_batch})\n",
    "            tot_loss = sess.run(EM_regularized_loss, feed_dict = {data_in: data_batch, labels_in: labels_batch, noise_in: noise_batch})\n",
    "            print(\"class_loss = {}, critic = {}, tot = {}\".format(class_loss, critic_val, tot_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = np.loadtxt(\"data_test.txt\")\n",
    "nuisances_test = np.loadtxt(\"nuisances_test.txt\")\n",
    "labels_test = np.loadtxt(\"labels_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig = data_test[labels_test == 1]\n",
    "bkg = data_test[labels_test == 0]\n",
    "noise_sig = np.random.uniform(low = 0.0, high = 1.0, size = sig.shape)\n",
    "noise_bkg = np.random.uniform(low = 0.0, high = 1.0, size = bkg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_sig = sess.run(classifier_output, feed_dict = {data_in: sig, noise_in: noise_sig})\n",
    "pred_bkg = sess.run(classifier_output, feed_dict = {data_in: bkg, noise_in: noise_bkg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = [sess.run(samples_model) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD9CAYAAABdoNd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([pred_sig[:,0], pred_bkg[:,0], target], label = ['sig', 'bkg', 'target bkg'], histtype = 'step', density = True, stacked = False, fill = False, bins = 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
