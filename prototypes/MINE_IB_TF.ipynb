{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, \\\n",
    "                        allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(n_samples):\n",
    "    data = []\n",
    "    pois = []\n",
    "    nuisances = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        poi = np.random.uniform(low = 0.0, high = 1.0)\n",
    "        nuisance = np.random.uniform(low = 0.0, high = 1.0)\n",
    "                \n",
    "        datum = np.random.multivariate_normal(mean = [poi, nuisance], cov = np.array([[1, 0.2], [0.2, 1]]))\n",
    "        \n",
    "        data.append(datum)\n",
    "        #pois.append(poi)\n",
    "        #nuisances.append(nuisance)\n",
    "        \n",
    "        pois.append(nuisance)\n",
    "        nuisances.append(poi)\n",
    "        \n",
    "    return np.array(data), np.array(pois), np.array(nuisances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train, pois_train, nuisances_train = prepare_data(80000)\n",
    "nuisances_train = np.expand_dims(nuisances_train, axis = 1)\n",
    "pois_train = np.expand_dims(pois_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hexbin(x = data_train[:, 0], y = data_train[:, 1], bins = 'log', gridsize = 50)\n",
    "plt.colorbar()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([-3, 4])\n",
    "ax.set_ylim([-3, 4])\n",
    "plt.savefig(\"toy_filterdataset.pdf\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MINE_network(data_X, data_Y, name):\n",
    "    with tf.variable_scope(name):\n",
    "        data_Y_shuffled = tf.random.shuffle(data_Y)\n",
    "    \n",
    "        data_X_combined = tf.concat([data_X, data_X], axis = 0)\n",
    "        data_Y_combined = tf.concat([data_Y, data_Y_shuffled], axis = 0)\n",
    "        data_combined = tf.concat([data_X_combined, data_Y_combined], axis = 1)\n",
    "        \n",
    "        lay = layers.relu(data_combined, 20)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 1)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = name)\n",
    "    \n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MINE_loss(MINE_output, name):\n",
    "    with tf.variable_scope(name):\n",
    "        batch_size_dyn = tf.cast(tf.math.divide(tf.shape(MINE_output)[0], 2), tf.int32)\n",
    "        T_xy = MINE_output[:batch_size_dyn,:]\n",
    "        T_x_y = MINE_output[batch_size_dyn:,:]\n",
    "        MINE_loss = -(tf.reduce_mean(T_xy, axis = 0) - tf.math.log(tf.reduce_mean(tf.math.exp(T_x_y), axis = 0)))\n",
    "        MINE_loss = MINE_loss[0]\n",
    "        \n",
    "    return MINE_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_network(filter_input):\n",
    "    with tf.variable_scope(\"filter\"):\n",
    "        lay = layers.relu(filter_input, 20)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 1)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"filter\")\n",
    "\n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare input tensors\n",
    "data_in = tf.placeholder(tf.float32, [None, 2], name = 'data_in')\n",
    "nuisances_in = tf.placeholder(tf.float32, [None, 1], name = 'nuisances_in')\n",
    "pois_in = tf.placeholder(tf.float32, [None, 1], name = 'pois_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_output, filter_vars = filter_network(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the two MINE blocks connected to the filter output\n",
    "MINE_output_nuis, MINE_vars_nuis = MINE_network(filter_output, nuisances_in, \"MINE_nuis\")\n",
    "MINE_output_pois, MINE_vars_pois = MINE_network(filter_output, pois_in, \"MINE_pois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upon convergence, the MINE losses below give the negative mutual information\n",
    "MINE_loss_nuis = MINE_loss(MINE_output_nuis, \"MINE_loss_nuis\")\n",
    "MINE_loss_pois = MINE_loss(MINE_output_pois, \"MINE_loss_pois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MINE optimizers\n",
    "train_MINE_pois = tf.train.AdamOptimizer(learning_rate = 0.01, beta1 = 0.3, beta2 = 0.5).minimize(MINE_loss_nuis, var_list = MINE_vars_nuis)\n",
    "train_MINE_nuis = tf.train.AdamOptimizer(learning_rate = 0.01, beta1 = 0.3, beta2 = 0.5).minimize(MINE_loss_pois, var_list = MINE_vars_pois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_loss = MINE_loss_pois - 3 * MINE_loss_nuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter optimizer\n",
    "train_filter = tf.train.AdamOptimizer(learning_rate = 0.005, beta1 = 0.3, beta2 = 0.5).minimize(total_loss, var_list = filter_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MINE_init_epochs = 200\n",
    "batches_per_epoch = 200\n",
    "number_epochs = 5\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-train MINE blocks\n",
    "for epoch in range(MINE_init_epochs):\n",
    "    sess.run(train_MINE_pois, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "    sess.run(train_MINE_nuis, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_nuis = 0.0011801719665527344, MI_pois = 0.029489874839782715\n"
     ]
    }
   ],
   "source": [
    "# initial MI values        \n",
    "MI_pois = -sess.run(MINE_loss_pois, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "MI_nuis = -sess.run(MINE_loss_nuis, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "\n",
    "print(\"MI_nuis = {}, MI_pois = {}\".format(MI_nuis, MI_pois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_nuis = -0.00016260147094726562, MI_pois = 0.033757805824279785\n",
      "MI_nuis = 0.0002808570861816406, MI_pois = 0.041840314865112305\n",
      "MI_nuis = 7.724761962890625e-05, MI_pois = 0.0430295467376709\n",
      "MI_nuis = 9.107589721679688e-05, MI_pois = 0.039037227630615234\n",
      "MI_nuis = 0.00011396408081054688, MI_pois = 0.04099607467651367\n",
      "MI_nuis = 0.000152587890625, MI_pois = 0.04218578338623047\n",
      "MI_nuis = 0.00042819976806640625, MI_pois = 0.04279899597167969\n",
      "MI_nuis = 0.00011444091796875, MI_pois = 0.04123973846435547\n",
      "MI_nuis = 0.0002956390380859375, MI_pois = 0.044158935546875\n",
      "MI_nuis = 0.00028133392333984375, MI_pois = 0.041080474853515625\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(number_epochs):\n",
    "    for batch in range(batches_per_epoch):\n",
    "        # prepare batch training data\n",
    "        inds = np.random.choice(len(data_train), batch_size)\n",
    "        data_batch = data_train[inds]\n",
    "        pois_batch = pois_train[inds]\n",
    "        nuis_batch = nuisances_train[inds]\n",
    "\n",
    "        # update MINE\n",
    "        sess.run(train_MINE_pois, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "        sess.run(train_MINE_nuis, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "\n",
    "        # update filter\n",
    "        sess.run(train_filter, feed_dict = {data_in: data_batch, nuisances_in: nuis_batch, pois_in: pois_batch})\n",
    "\n",
    "        if not batch % 100:\n",
    "            # debug output\n",
    "            MI_pois = -sess.run(MINE_loss_pois, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "            MI_nuis = -sess.run(MINE_loss_nuis, feed_dict = {data_in: data_train, nuisances_in: nuisances_train, pois_in: pois_train})\n",
    "\n",
    "            print(\"MI_nuis = {}, MI_pois = {}\".format(MI_nuis, MI_pois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the filter output as a function of the incoming random variable\n",
    "data_test = np.random.uniform(low = -4, high = 4, size = [50000, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = sess.run(filter_output, feed_dict = {data_in: data_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_contour(data_xy, data_z, x_low = -4, x_high = 4 , y_low = -4, y_high = 4):\n",
    "    from matplotlib.mlab import griddata\n",
    "    \n",
    "    xi = np.linspace(x_low, x_high, 1000)\n",
    "    yi = np.linspace(y_low, y_high, 1000)\n",
    "    zi = griddata(data_xy[:, 0], data_xy[:, 1], data_z, xi, yi, interp = \"linear\")\n",
    "\n",
    "    plt.contourf(xi, yi, zi, interp='linear', levels = 20)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel/__main__.py:6: MatplotlibDeprecationWarning: The griddata function was deprecated in Matplotlib 2.2 and will be removed in 3.1. Use scipy.interpolate.griddata instead.\n",
      "/home/philipp/.local/lib/python3.5/site-packages/matplotlib/contour.py:1000: UserWarning: The following kwargs were not used by contour: 'interp'\n",
      "  s)\n"
     ]
    }
   ],
   "source": [
    "plot_contour(data_test, pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig(\"information_filter_contours_f2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
