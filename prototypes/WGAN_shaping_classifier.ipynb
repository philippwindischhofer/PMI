{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "import tensorflow.contrib.distributions as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, \\\n",
    "                        allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_loc = -0.25\n",
    "target_scale = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(n_samples):\n",
    "    data = []\n",
    "    labels = []\n",
    "    nuisances = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        sig_bkg = np.random.uniform(low = 0.0, high = 1.0, size = 1)\n",
    "        if sig_bkg > 0.5:\n",
    "            nuisance = np.random.uniform(low = 0.0, high = 2.0, size = 1)\n",
    "            data.append(np.random.multivariate_normal(mean = [0.0, nuisance], cov = np.array([[1, -0.5], [-0.5, 1]]), size = 1).flatten())\n",
    "            labels.append(1.0)\n",
    "        else:\n",
    "            nuisance = np.random.uniform(low = 0.0, high = 2.0, size = 1)\n",
    "            data.append(np.random.multivariate_normal(mean = [1.0, nuisance], cov = np.eye(2), size = 1).flatten())\n",
    "            labels.append(0.0)\n",
    "            \n",
    "        nuisances.append(nuisance)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    nuisances = np.array(nuisances)\n",
    "    \n",
    "    return data, labels, nuisances.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "data_train, labels_train, nuisances_train = prepare_data(num_samples)\n",
    "nuisances_train = np.expand_dims(nuisances_train, axis = 1)\n",
    "labels_train = np.expand_dims(labels_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_bkg = labels_train == 0\n",
    "bkg_data_train = data_train[train_bkg.flatten()]\n",
    "bkg_labels_train = labels_train[train_bkg.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sig = labels_train == 1\n",
    "sig_data_train = data_train[train_sig.flatten()]\n",
    "sig_labels_train = labels_train[train_sig.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier(data_in, name):\n",
    "    with tf.variable_scope(name, reuse = tf.AUTO_REUSE):\n",
    "        lay = layers.relu(data_in, 40)\n",
    "        lay = layers.relu(lay, 40)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 2)\n",
    "        normalized_outputs = layers.softmax(outputs)\n",
    "\n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = name)\n",
    "\n",
    "    return outputs, normalized_outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EM_network(data, name):\n",
    "    with tf.variable_scope(name, reuse = tf.AUTO_REUSE):       \n",
    "        lay = layers.relu(data, 40)\n",
    "        lay = layers.relu(lay, 40)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 1)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = name)\n",
    "    \n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_EM_loss(data_P, data_Q, name):\n",
    "    local_EM_network_name = name + \"_EM_net\"\n",
    "    \n",
    "    # generator output\n",
    "    T_P, EM_vars = EM_network(data_P, name = local_EM_network_name)\n",
    "    \n",
    "    # target\n",
    "    T_Q, _ = EM_network(data_Q, name = local_EM_network_name)\n",
    "\n",
    "    EM_loss = tf.reduce_mean(T_P, axis = 0) - tf.reduce_mean(T_Q, axis = 0)\n",
    "    \n",
    "    batch_size_dyn = tf.cast(tf.shape(T_P)[0], tf.int32)\n",
    "    rand = tf.random.uniform(shape = (batch_size_dyn, 1), minval = 0.0, maxval = 1.0)\n",
    "    \n",
    "    # add gradient penalty\n",
    "    x_grad = tf.math.add(tf.math.multiply(rand, data_P),\n",
    "                         tf.math.multiply(tf.math.subtract(1.0, rand), data_Q))\n",
    "    x_grad_EM, _ = EM_network(x_grad, name = local_EM_network_name)\n",
    "    grad = tf.gradients(x_grad_EM, x_grad)[0]\n",
    "    \n",
    "    grad_norm = tf.math.sqrt(tf.reduce_sum(tf.math.square(grad), axis = 1) + eps)\n",
    "    \n",
    "    grad_pen = tf.reduce_mean(tf.math.square(grad_norm - 1.0))\n",
    "\n",
    "    EM_loss_grad_pen = EM_loss[0] + 10 * grad_pen\n",
    "\n",
    "    return EM_loss_grad_pen, EM_vars, -EM_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_plots():\n",
    "    batch_size_test = 10000\n",
    "    target_test = np.random.normal(loc = target_loc, scale = target_scale, size = (batch_size_test, 1))\n",
    "        \n",
    "    inds_bkg = np.random.choice(len(bkg_data_train), int(batch_size_test / 2))\n",
    "    bkg_batch_data = bkg_data_train[inds_bkg]\n",
    "    bkg_batch_labels = bkg_labels_train[inds_bkg]\n",
    "\n",
    "    inds_sig = np.random.choice(len(sig_data_train), int(batch_size_test / 2))\n",
    "    sig_batch_data = sig_data_train[inds_sig]\n",
    "    sig_batch_labels = sig_labels_train[inds_sig]\n",
    "    \n",
    "    class_pred_bkg = sess.run(class_out_single, feed_dict = {data_in: bkg_batch_data, labels_in: bkg_batch_labels})\n",
    "    class_pred_sig = sess.run(class_out_single, feed_dict = {data_in: sig_batch_data, labels_in: sig_batch_labels})\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.hist([np.squeeze(target_test), np.squeeze(class_pred_bkg), np.squeeze(class_pred_sig)], label = ['bkg target', 'classifier bkg', 'classifier sig'], histtype = 'step', density = True, bins = 50)\n",
    "    plt.xlim([-0.5, 0.0])\n",
    "    plt.ylim([0, 10])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_in = tf.placeholder(tf.float32, [None, 2], name = 'data_in')\n",
    "target_in = tf.placeholder(tf.float32, [None, 1], name = 'target_in')\n",
    "labels_in = tf.placeholder(tf.float32, [None, 1], name = 'labels_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_out, norm_class_out, gen_vars = classifier(data_in, \"gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_one_hot = tf.squeeze(tf.one_hot(tf.dtypes.cast(labels_in, tf.int32), depth = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_loss = tf.losses.softmax_cross_entropy(onehot_labels = labels_one_hot, logits = norm_class_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bkg_truth = tf.where(tf.math.less(labels_in, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_out_single = tf.expand_dims(class_out[:,1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_out_bkg = tf.gather_nd(class_out_single, bkg_truth)\n",
    "class_out_bkg = tf.expand_dims(class_out_bkg, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EM_lossval, EM_vars, EM_dist = make_EM_loss(class_out_bkg, target_in, \"EM_loss_obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_loss = classification_loss + EM_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_EM = tf.train.AdamOptimizer(learning_rate = 5e-3, beta1 = 0.0, beta2 = 0.5).minimize(EM_lossval, var_list = EM_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = tf.train.AdamOptimizer(learning_rate = 1e-4, beta1 = 0.0, beta2 = 0.5).minimize(EM_dist, var_list = gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_class_total_loss = tf.train.AdamOptimizer(learning_rate = 1e-4, beta1 = 0.0, beta2 = 0.5).minimize(total_loss, var_list = gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_class = tf.train.AdamOptimizer(learning_rate = 1e-4, beta1 = 0.0, beta2 = 0.5).minimize(classification_loss, var_list = gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_critic = tf.variables_initializer(EM_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM_dist = [0.01784618]\n",
      "EM_dist = [0.01483873]\n",
      "EM_dist = [0.01632118]\n",
      "EM_dist = [0.01740743]\n",
      "EM_dist = [0.01648913]\n",
      "EM_dist = [0.01717007]\n",
      "EM_dist = [0.01478389]\n",
      "EM_dist = [0.01453142]\n",
      "EM_dist = [0.02103731]\n",
      "EM_dist = [0.01278923]\n",
      "EM_dist = [0.01745604]\n",
      "EM_dist = [0.0117452]\n",
      "EM_dist = [0.01836996]\n",
      "EM_dist = [0.01343191]\n",
      "EM_dist = [0.01741756]\n",
      "EM_dist = [0.01603058]\n",
      "EM_dist = [0.01969416]\n",
      "EM_dist = [0.01537956]\n",
      "EM_dist = [0.02084211]\n",
      "EM_dist = [0.01569737]\n",
      "EM_dist = [0.01981172]\n",
      "EM_dist = [0.01386051]\n",
      "EM_dist = [0.02244923]\n",
      "EM_dist = [0.02150802]\n",
      "EM_dist = [0.01897602]\n",
      "EM_dist = [0.01339903]\n",
      "EM_dist = [0.01235914]\n",
      "EM_dist = [0.01501293]\n",
      "EM_dist = [0.01924494]\n",
      "EM_dist = [0.01737118]\n",
      "EM_dist = [0.0191154]\n",
      "EM_dist = [0.01121032]\n",
      "EM_dist = [0.01463257]\n",
      "EM_dist = [0.01468648]\n",
      "EM_dist = [0.02112971]\n",
      "EM_dist = [0.0140285]\n",
      "EM_dist = [0.01574492]\n",
      "EM_dist = [0.0139529]\n",
      "EM_dist = [0.01666832]\n",
      "EM_dist = [0.01458722]\n",
      "EM_dist = [0.01988675]\n",
      "EM_dist = [0.01206346]\n",
      "EM_dist = [0.01868829]\n",
      "EM_dist = [0.01465733]\n",
      "EM_dist = [0.01883535]\n",
      "EM_dist = [0.01689677]\n",
      "EM_dist = [0.01432347]\n",
      "EM_dist = [0.0159566]\n",
      "EM_dist = [0.0233665]\n",
      "EM_dist = [0.01362942]\n",
      "EM_dist = [0.01650646]\n",
      "EM_dist = [0.01479763]\n",
      "EM_dist = [0.01873717]\n",
      "EM_dist = [0.01261693]\n",
      "EM_dist = [0.01887202]\n",
      "EM_dist = [0.01795235]\n",
      "EM_dist = [0.01402356]\n",
      "EM_dist = [0.0178622]\n",
      "EM_dist = [0.01652563]\n",
      "EM_dist = [0.01790558]\n",
      "EM_dist = [0.01644556]\n",
      "EM_dist = [0.01495998]\n",
      "EM_dist = [0.01735479]\n",
      "EM_dist = [0.01547708]\n",
      "EM_dist = [0.02077262]\n",
      "EM_dist = [0.01253772]\n",
      "EM_dist = [0.01988524]\n",
      "EM_dist = [0.01510841]\n",
      "EM_dist = [0.01881804]\n",
      "EM_dist = [0.01589926]\n",
      "EM_dist = [0.01813698]\n",
      "EM_dist = [0.01398532]\n",
      "EM_dist = [0.01688014]\n",
      "EM_dist = [0.01477574]\n",
      "EM_dist = [0.01617813]\n",
      "EM_dist = [0.0160345]\n",
      "EM_dist = [0.01870759]\n",
      "EM_dist = [0.01589771]\n",
      "EM_dist = [0.01493809]\n",
      "EM_dist = [0.01676798]\n",
      "EM_dist = [0.0184565]\n",
      "EM_dist = [0.01479343]\n",
      "EM_dist = [0.01735169]\n",
      "EM_dist = [0.01711026]\n",
      "EM_dist = [0.01416782]\n",
      "EM_dist = [0.01764551]\n",
      "EM_dist = [0.01808137]\n",
      "EM_dist = [0.01858817]\n",
      "EM_dist = [0.01634218]\n",
      "EM_dist = [0.01609659]\n",
      "EM_dist = [0.01479997]\n",
      "EM_dist = [0.0144964]\n",
      "EM_dist = [0.01696214]\n",
      "EM_dist = [0.01600312]\n",
      "EM_dist = [0.01680212]\n",
      "EM_dist = [0.01544945]\n",
      "EM_dist = [0.01877482]\n",
      "EM_dist = [0.01959831]\n",
      "EM_dist = [0.016165]\n",
      "EM_dist = [0.01506338]\n",
      "EM_dist = [0.01575907]\n",
      "EM_dist = [0.01610202]\n",
      "EM_dist = [0.01775859]\n",
      "EM_dist = [0.0111904]\n",
      "EM_dist = [0.0169463]\n",
      "EM_dist = [0.01823337]\n",
      "EM_dist = [0.02174343]\n",
      "EM_dist = [0.01579455]\n",
      "EM_dist = [0.0186166]\n",
      "EM_dist = [0.01523174]\n",
      "EM_dist = [0.01775689]\n",
      "EM_dist = [0.01706614]\n",
      "EM_dist = [0.01638691]\n",
      "EM_dist = [0.01359171]\n",
      "EM_dist = [0.01893362]\n",
      "EM_dist = [0.01801679]\n",
      "EM_dist = [0.01845533]\n",
      "EM_dist = [0.01219045]\n",
      "EM_dist = [0.01831396]\n",
      "EM_dist = [0.01834965]\n",
      "EM_dist = [0.01358335]\n",
      "EM_dist = [0.01174489]\n",
      "EM_dist = [0.01871468]\n",
      "EM_dist = [0.01747304]\n",
      "EM_dist = [0.01656093]\n",
      "EM_dist = [0.01326109]\n",
      "EM_dist = [0.01716726]\n",
      "EM_dist = [0.01737756]\n",
      "EM_dist = [0.01358952]\n",
      "EM_dist = [0.01811247]\n",
      "EM_dist = [0.01831995]\n",
      "EM_dist = [0.01624313]\n",
      "EM_dist = [0.01854484]\n",
      "EM_dist = [0.01763348]\n",
      "EM_dist = [0.02030587]\n",
      "EM_dist = [0.01461446]\n",
      "EM_dist = [0.01193053]\n",
      "EM_dist = [0.01643884]\n",
      "EM_dist = [0.01798654]\n",
      "EM_dist = [0.01722434]\n",
      "EM_dist = [0.0143293]\n",
      "EM_dist = [0.0221764]\n",
      "EM_dist = [0.01177281]\n",
      "EM_dist = [0.01700662]\n",
      "EM_dist = [0.0152012]\n",
      "EM_dist = [0.01485831]\n",
      "EM_dist = [0.02140968]\n",
      "EM_dist = [0.01577835]\n",
      "EM_dist = [0.01871686]\n",
      "EM_dist = [0.01721954]\n",
      "EM_dist = [0.02210049]\n",
      "EM_dist = [0.01572056]\n",
      "EM_dist = [0.01983827]\n",
      "EM_dist = [0.01383774]\n",
      "EM_dist = [0.02083246]\n",
      "EM_dist = [0.01903534]\n",
      "EM_dist = [0.02069259]\n",
      "EM_dist = [0.0168968]\n",
      "EM_dist = [0.01482859]\n",
      "EM_dist = [0.01858948]\n",
      "EM_dist = [0.0182099]\n",
      "EM_dist = [0.01818189]\n",
      "EM_dist = [0.01311158]\n",
      "EM_dist = [0.01411593]\n",
      "EM_dist = [0.01819663]\n",
      "EM_dist = [0.01451951]\n",
      "EM_dist = [0.01903465]\n",
      "EM_dist = [0.01408386]\n",
      "EM_dist = [0.0142957]\n",
      "EM_dist = [0.01911539]\n",
      "EM_dist = [0.01654787]\n",
      "EM_dist = [0.01535569]\n",
      "EM_dist = [0.01450323]\n",
      "EM_dist = [0.01411778]\n",
      "EM_dist = [0.01984258]\n",
      "EM_dist = [0.01332951]\n",
      "EM_dist = [0.01493521]\n",
      "EM_dist = [0.01207009]\n",
      "EM_dist = [0.01530129]\n",
      "EM_dist = [0.01519449]\n",
      "EM_dist = [0.01902929]\n",
      "EM_dist = [0.01296054]\n",
      "EM_dist = [0.01473972]\n",
      "EM_dist = [0.01620901]\n",
      "EM_dist = [0.01782164]\n",
      "EM_dist = [0.01861353]\n",
      "EM_dist = [0.01963602]\n",
      "EM_dist = [0.01976681]\n",
      "EM_dist = [0.01532407]\n",
      "EM_dist = [0.01453976]\n",
      "EM_dist = [0.01819035]\n",
      "EM_dist = [0.01449105]\n",
      "EM_dist = [0.01845598]\n",
      "EM_dist = [0.01410449]\n",
      "EM_dist = [0.02006096]\n",
      "EM_dist = [0.01462653]\n",
      "EM_dist = [0.02131389]\n",
      "EM_dist = [0.01674515]\n",
      "EM_dist = [0.01958649]\n",
      "EM_dist = [0.01742651]\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    target = np.random.normal(loc = target_loc, scale = target_scale, size = (batch_size, 1))\n",
    "    inds = np.random.choice(len(bkg_data_train), batch_size)\n",
    "    data_batch = bkg_data_train[inds]\n",
    "    labels_batch = bkg_labels_train[inds]\n",
    "    \n",
    "    sess.run(train_EM, feed_dict = {data_in: data_batch, target_in: target, labels_in: labels_batch})\n",
    "\n",
    "    EM_dist_val = sess.run(EM_dist, feed_dict = {data_in: data_batch, target_in: target, labels_in: labels_batch})\n",
    "    print(\"EM_dist = {}\".format(EM_dist_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plots()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perform_training(training_op, epochs, ME_epochs):\n",
    "    for i in range(0, epochs):\n",
    "        # prepare noise\n",
    "        for j in range(ME_epochs):\n",
    "            target = np.random.normal(loc = target_loc, scale = target_scale, size = (batch_size, 1))\n",
    "            inds = np.random.choice(len(bkg_data_train), batch_size)\n",
    "            bkg_batch_data = bkg_data_train[inds]\n",
    "            bkg_batch_labels = bkg_labels_train[inds]\n",
    "\n",
    "            sess.run(train_EM, feed_dict = {data_in: bkg_batch_data, target_in: target, labels_in: bkg_batch_labels})\n",
    "\n",
    "        target = np.random.normal(loc = target_loc, scale = target_scale, size = (int(batch_size / 2), 1))\n",
    "        inds = np.random.choice(len(data_train), batch_size)\n",
    "        data_batch = data_train[inds]\n",
    "\n",
    "        inds_bkg = np.random.choice(len(bkg_data_train), int(batch_size / 2))\n",
    "        bkg_batch_data = bkg_data_train[inds_bkg]\n",
    "        bkg_batch_labels = bkg_labels_train[inds_bkg]\n",
    "\n",
    "        inds_sig = np.random.choice(len(sig_data_train), int(batch_size / 2))\n",
    "        sig_batch_data = sig_data_train[inds_sig]\n",
    "        sig_batch_labels = sig_labels_train[inds_sig]\n",
    "\n",
    "        data_batch = np.concatenate([sig_batch_data, bkg_batch_data])\n",
    "        labels_batch = np.concatenate([sig_batch_labels, bkg_batch_labels])\n",
    "        \n",
    "        sess.run(training_op, feed_dict = {data_in: data_batch, target_in: target, labels_in: labels_batch})\n",
    "        EM_dist_val = sess.run(EM_dist, feed_dict = {data_in: data_batch, target_in: target, labels_in: labels_batch})\n",
    "        critic_loss = sess.run(EM_lossval, feed_dict = {data_in: data_batch, target_in: target, labels_in: labels_batch})\n",
    "        class_lossval = sess.run(classification_loss, feed_dict = {data_in: data_batch, target_in: target, labels_in: labels_batch})\n",
    "\n",
    "        print(\"W = {}\".format(EM_dist_val))\n",
    "        print(\"critic loss = {}\".format(critic_loss))\n",
    "        print(\"class loss = {}\".format(class_lossval))\n",
    "\n",
    "        #save_plots(\"WGAN_training/epoch_\" + str(i).zfill(5) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [0.00380835]\n",
      "critic loss = 0.009147841483354568\n",
      "class loss = 0.6538085341453552\n"
     ]
    }
   ],
   "source": [
    "perform_training(train_class_total_loss, epochs = 1, ME_epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [0.04910219]\n",
      "critic loss = -0.04368305206298828\n",
      "class loss = 0.7056863903999329\n",
      "W = [0.03576565]\n",
      "critic loss = -0.031983718276023865\n",
      "class loss = 0.7016664147377014\n",
      "W = [0.04677147]\n",
      "critic loss = -0.041941165924072266\n",
      "class loss = 0.7047515511512756\n",
      "W = [0.04754257]\n",
      "critic loss = -0.042457252740859985\n",
      "class loss = 0.7038659453392029\n",
      "W = [0.04030138]\n",
      "critic loss = -0.03557813912630081\n",
      "class loss = 0.7046754360198975\n",
      "W = [0.04274517]\n",
      "critic loss = -0.03822920098900795\n",
      "class loss = 0.7037270665168762\n",
      "W = [0.04542476]\n",
      "critic loss = -0.0409938246011734\n",
      "class loss = 0.7047550678253174\n",
      "W = [0.04577142]\n",
      "critic loss = -0.033603645861148834\n",
      "class loss = 0.7025068402290344\n",
      "W = [0.04692531]\n",
      "critic loss = -0.042072806507349014\n",
      "class loss = 0.7018827795982361\n",
      "W = [0.05178511]\n",
      "critic loss = -0.04757292941212654\n",
      "class loss = 0.7020091414451599\n",
      "W = [0.05592316]\n",
      "critic loss = -0.05149534344673157\n",
      "class loss = 0.7003287076950073\n",
      "W = [0.0471496]\n",
      "critic loss = -0.04247903823852539\n",
      "class loss = 0.7009677886962891\n",
      "W = [0.04522663]\n",
      "critic loss = -0.042263031005859375\n",
      "class loss = 0.7005966901779175\n",
      "W = [0.04576552]\n",
      "critic loss = -0.04135362058877945\n",
      "class loss = 0.7000792026519775\n",
      "W = [0.03987545]\n",
      "critic loss = -0.035703014582395554\n",
      "class loss = 0.6985146403312683\n",
      "W = [0.05053294]\n",
      "critic loss = -0.048172857612371445\n",
      "class loss = 0.6991585493087769\n",
      "W = [0.0480206]\n",
      "critic loss = -0.04389341175556183\n",
      "class loss = 0.6975888013839722\n",
      "W = [0.05566257]\n",
      "critic loss = -0.05159411206841469\n",
      "class loss = 0.6992133855819702\n",
      "W = [0.04831517]\n",
      "critic loss = -0.04720497131347656\n",
      "class loss = 0.6971061825752258\n",
      "W = [0.04511625]\n",
      "critic loss = -0.04077565297484398\n",
      "class loss = 0.6980595588684082\n",
      "W = [0.0466612]\n",
      "critic loss = -0.04352307319641113\n",
      "class loss = 0.6954918503761292\n",
      "W = [0.04564363]\n",
      "critic loss = -0.042118221521377563\n",
      "class loss = 0.6949037909507751\n",
      "W = [0.04737061]\n",
      "critic loss = -0.036358416080474854\n",
      "class loss = 0.6949173212051392\n",
      "W = [0.05221283]\n",
      "critic loss = -0.0479142963886261\n",
      "class loss = 0.6957430243492126\n",
      "W = [0.0414924]\n",
      "critic loss = -0.032729633152484894\n",
      "class loss = 0.6936787962913513\n",
      "W = [0.05003923]\n",
      "critic loss = -0.047514285892248154\n",
      "class loss = 0.6935815215110779\n",
      "W = [0.04433048]\n",
      "critic loss = -0.043964993208646774\n",
      "class loss = 0.6939622759819031\n",
      "W = [0.04679388]\n",
      "critic loss = -0.042045094072818756\n",
      "class loss = 0.692429780960083\n",
      "W = [0.05250508]\n",
      "critic loss = -0.05031181871891022\n",
      "class loss = 0.6928850412368774\n",
      "W = [0.05535203]\n",
      "critic loss = -0.0552811361849308\n",
      "class loss = 0.6923911571502686\n",
      "W = [0.05159163]\n",
      "critic loss = -0.04677437245845795\n",
      "class loss = 0.6901043653488159\n",
      "W = [0.05386758]\n",
      "critic loss = -0.05350391939282417\n",
      "class loss = 0.6912422776222229\n",
      "W = [0.04889029]\n",
      "critic loss = -0.046226680278778076\n",
      "class loss = 0.6902198195457458\n",
      "W = [0.0415675]\n",
      "critic loss = -0.03827419504523277\n",
      "class loss = 0.6887851357460022\n",
      "W = [0.04541254]\n",
      "critic loss = -0.04273161664605141\n",
      "class loss = 0.6885866522789001\n",
      "W = [0.05605698]\n",
      "critic loss = -0.05136231705546379\n",
      "class loss = 0.6902701258659363\n",
      "W = [0.05668354]\n",
      "critic loss = -0.05309704691171646\n",
      "class loss = 0.6895673871040344\n",
      "W = [0.0419898]\n",
      "critic loss = -0.040451642125844955\n",
      "class loss = 0.6878059506416321\n",
      "W = [0.05055356]\n",
      "critic loss = -0.05009967088699341\n",
      "class loss = 0.6876263618469238\n",
      "W = [0.04923773]\n",
      "critic loss = -0.044763337820768356\n",
      "class loss = 0.6875320076942444\n",
      "W = [0.0492636]\n",
      "critic loss = -0.04833335429430008\n",
      "class loss = 0.6861203908920288\n",
      "W = [0.05287731]\n",
      "critic loss = -0.0520249642431736\n",
      "class loss = 0.6854375004768372\n",
      "W = [0.05215871]\n",
      "critic loss = -0.047470416873693466\n",
      "class loss = 0.6864747405052185\n",
      "W = [0.05635619]\n",
      "critic loss = -0.05138900503516197\n",
      "class loss = 0.6853106021881104\n",
      "W = [0.05535829]\n",
      "critic loss = -0.05420709773898125\n",
      "class loss = 0.6853592395782471\n",
      "W = [0.05069172]\n",
      "critic loss = -0.05018702894449234\n",
      "class loss = 0.6819053888320923\n",
      "W = [0.05230498]\n",
      "critic loss = -0.0510682538151741\n",
      "class loss = 0.6843575239181519\n",
      "W = [0.04888666]\n",
      "critic loss = -0.04525001719594002\n",
      "class loss = 0.6827214360237122\n",
      "W = [0.05849028]\n",
      "critic loss = -0.054677534848451614\n",
      "class loss = 0.6804235577583313\n",
      "W = [0.04914153]\n",
      "critic loss = -0.04537950083613396\n",
      "class loss = 0.6794764399528503\n",
      "W = [0.04749024]\n",
      "critic loss = -0.045368362218141556\n",
      "class loss = 0.6823096871376038\n",
      "W = [0.04886079]\n",
      "critic loss = -0.04677974805235863\n",
      "class loss = 0.6817812323570251\n",
      "W = [0.05281842]\n",
      "critic loss = -0.05072012543678284\n",
      "class loss = 0.6800971031188965\n",
      "W = [0.04522502]\n",
      "critic loss = -0.04304404929280281\n",
      "class loss = 0.6779007911682129\n",
      "W = [0.05102026]\n",
      "critic loss = -0.04889326170086861\n",
      "class loss = 0.6783403754234314\n",
      "W = [0.05482745]\n",
      "critic loss = -0.052667517215013504\n",
      "class loss = 0.6779108643531799\n",
      "W = [0.052724]\n",
      "critic loss = -0.05079896003007889\n",
      "class loss = 0.6788309216499329\n",
      "W = [0.05536366]\n",
      "critic loss = -0.05328400433063507\n",
      "class loss = 0.6788061261177063\n",
      "W = [0.04839706]\n",
      "critic loss = -0.04622446373105049\n",
      "class loss = 0.6766448020935059\n",
      "W = [0.04871619]\n",
      "critic loss = -0.04641638696193695\n",
      "class loss = 0.6787714958190918\n",
      "W = [0.05701315]\n",
      "critic loss = -0.054845768958330154\n",
      "class loss = 0.6769551038742065\n",
      "W = [0.04578817]\n",
      "critic loss = -0.04377385973930359\n",
      "class loss = 0.6751407384872437\n",
      "W = [0.05992913]\n",
      "critic loss = -0.05777578055858612\n",
      "class loss = 0.6776499152183533\n",
      "W = [0.05733645]\n",
      "critic loss = -0.05526432394981384\n",
      "class loss = 0.6751337051391602\n",
      "W = [0.05154395]\n",
      "critic loss = -0.049527913331985474\n",
      "class loss = 0.6768261790275574\n",
      "W = [0.04849958]\n",
      "critic loss = -0.04631577432155609\n",
      "class loss = 0.6751700043678284\n",
      "W = [0.05376101]\n",
      "critic loss = -0.05164305493235588\n",
      "class loss = 0.6731219291687012\n",
      "W = [0.04892612]\n",
      "critic loss = -0.046948667615652084\n",
      "class loss = 0.671287477016449\n",
      "W = [0.05740643]\n",
      "critic loss = -0.05536723509430885\n",
      "class loss = 0.6721804141998291\n",
      "W = [0.05117154]\n",
      "critic loss = -0.049021895974874496\n",
      "class loss = 0.6725215315818787\n",
      "W = [0.05205703]\n",
      "critic loss = -0.050097811967134476\n",
      "class loss = 0.670474648475647\n",
      "W = [0.04861534]\n",
      "critic loss = -0.04642101377248764\n",
      "class loss = 0.672994077205658\n",
      "W = [0.04604948]\n",
      "critic loss = -0.04390648379921913\n",
      "class loss = 0.668915867805481\n",
      "W = [0.05188525]\n",
      "critic loss = -0.04982200264930725\n",
      "class loss = 0.6679733991622925\n",
      "W = [0.04862571]\n",
      "critic loss = -0.046507544815540314\n",
      "class loss = 0.6661124229431152\n",
      "W = [0.0471487]\n",
      "critic loss = -0.044961847364902496\n",
      "class loss = 0.670317530632019\n",
      "W = [0.04720652]\n",
      "critic loss = -0.044993139803409576\n",
      "class loss = 0.6663632988929749\n",
      "W = [0.05812037]\n",
      "critic loss = -0.05602066218852997\n",
      "class loss = 0.6694085001945496\n",
      "W = [0.05281544]\n",
      "critic loss = -0.051257457584142685\n",
      "class loss = 0.6676061749458313\n",
      "W = [0.05372345]\n",
      "critic loss = -0.05130346119403839\n",
      "class loss = 0.666129469871521\n",
      "W = [0.04966509]\n",
      "critic loss = -0.04785234481096268\n",
      "class loss = 0.6674136519432068\n",
      "W = [0.0438292]\n",
      "critic loss = -0.041379377245903015\n",
      "class loss = 0.6659337878227234\n",
      "W = [0.04683506]\n",
      "critic loss = -0.04475686699151993\n",
      "class loss = 0.6652365922927856\n",
      "W = [0.0498234]\n",
      "critic loss = -0.04844256490468979\n",
      "class loss = 0.667724609375\n",
      "W = [0.05036092]\n",
      "critic loss = -0.048218004405498505\n",
      "class loss = 0.6655464768409729\n",
      "W = [0.05279768]\n",
      "critic loss = -0.05073748156428337\n",
      "class loss = 0.6652740240097046\n",
      "W = [0.04339552]\n",
      "critic loss = -0.041479289531707764\n",
      "class loss = 0.6619107127189636\n",
      "W = [0.0421443]\n",
      "critic loss = -0.040065765380859375\n",
      "class loss = 0.6628454327583313\n",
      "W = [0.0493834]\n",
      "critic loss = -0.04715229570865631\n",
      "class loss = 0.6613577604293823\n",
      "W = [0.06087375]\n",
      "critic loss = -0.05967208743095398\n",
      "class loss = 0.6638026237487793\n",
      "W = [0.04731047]\n",
      "critic loss = -0.044783517718315125\n",
      "class loss = 0.6630381941795349\n",
      "W = [0.04139566]\n",
      "critic loss = -0.03976621851325035\n",
      "class loss = 0.6600278615951538\n",
      "W = [0.05027962]\n",
      "critic loss = -0.04892128333449364\n",
      "class loss = 0.6621071696281433\n",
      "W = [0.04652536]\n",
      "critic loss = -0.04457787051796913\n",
      "class loss = 0.6623316407203674\n",
      "W = [0.0593127]\n",
      "critic loss = -0.05772789567708969\n",
      "class loss = 0.6626377701759338\n",
      "W = [0.05026066]\n",
      "critic loss = -0.048894431442022324\n",
      "class loss = 0.6619788408279419\n",
      "W = [0.05145216]\n",
      "critic loss = -0.050220660865306854\n",
      "class loss = 0.6594991683959961\n",
      "W = [0.03628576]\n",
      "critic loss = -0.03454921394586563\n",
      "class loss = 0.6549690961837769\n",
      "W = [0.05955124]\n",
      "critic loss = -0.0578053817152977\n",
      "class loss = 0.6594347357749939\n",
      "W = [0.04386413]\n",
      "critic loss = -0.04226619005203247\n",
      "class loss = 0.6595205068588257\n"
     ]
    }
   ],
   "source": [
    "perform_training(train_class, epochs = 100, ME_epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [0.05281776]\n",
      "critic loss = -0.046695198863744736\n",
      "class loss = 0.6674094200134277\n",
      "W = [0.05014825]\n",
      "critic loss = -0.037474364042282104\n",
      "class loss = 0.6632840633392334\n",
      "W = [0.05823225]\n",
      "critic loss = -0.0533597394824028\n",
      "class loss = 0.6638917326927185\n",
      "W = [0.04700744]\n",
      "critic loss = -0.036338575184345245\n",
      "class loss = 0.6641810536384583\n",
      "W = [0.05443782]\n",
      "critic loss = -0.047229617834091187\n",
      "class loss = 0.6669999361038208\n",
      "W = [0.04641163]\n",
      "critic loss = -0.038591381162405014\n",
      "class loss = 0.6668498516082764\n",
      "W = [0.04290015]\n",
      "critic loss = -0.03716224431991577\n",
      "class loss = 0.6664512753486633\n",
      "W = [0.04972005]\n",
      "critic loss = -0.043012917041778564\n",
      "class loss = 0.6647153496742249\n",
      "W = [0.04718584]\n",
      "critic loss = -0.03900592029094696\n",
      "class loss = 0.665987491607666\n",
      "W = [0.04797709]\n",
      "critic loss = -0.03874361515045166\n",
      "class loss = 0.6662145853042603\n",
      "W = [0.04696822]\n",
      "critic loss = -0.03952150046825409\n",
      "class loss = 0.6675902009010315\n",
      "W = [0.04652452]\n",
      "critic loss = -0.039733629673719406\n",
      "class loss = 0.6684131622314453\n",
      "W = [0.04689509]\n",
      "critic loss = -0.04181704297661781\n",
      "class loss = 0.669723629951477\n",
      "W = [0.04267418]\n",
      "critic loss = -0.03517283499240875\n",
      "class loss = 0.6688496470451355\n",
      "W = [0.03714937]\n",
      "critic loss = -0.03184463083744049\n",
      "class loss = 0.666778564453125\n",
      "W = [0.04012638]\n",
      "critic loss = -0.030523378401994705\n",
      "class loss = 0.6675129532814026\n",
      "W = [0.0458613]\n",
      "critic loss = -0.04076506942510605\n",
      "class loss = 0.6687912940979004\n",
      "W = [0.04152495]\n",
      "critic loss = -0.03522856533527374\n",
      "class loss = 0.6672433018684387\n",
      "W = [0.03801131]\n",
      "critic loss = -0.029966164380311966\n",
      "class loss = 0.6701350212097168\n",
      "W = [0.03826785]\n",
      "critic loss = -0.03318304941058159\n",
      "class loss = 0.666522741317749\n"
     ]
    }
   ],
   "source": [
    "perform_training(train_gen, epochs = 20, ME_epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_plots()\n",
    "#plt.show()\n",
    "plt.savefig(\"shaped_classifier.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = np.loadtxt(\"data_test.txt\")\n",
    "labels_test = np.loadtxt(\"labels_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = sess.run(norm_class_out, feed_dict = {data_in: data_test})[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LL_pred = np.loadtxt(\"LL_evaluated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr_LL, tpr_LL, thresholds_LL = metrics.roc_curve(labels_test, LL_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot both of them into the same graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tpr, fpr, label = 'shaped classifier', c = 'red')\n",
    "ax.plot(fpr_LL, tpr_LL, label = 'analytic likelihood', c = 'black', ls = 'dashed')\n",
    "leg = ax.legend(loc = 'lower right')\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "#plt.show()\n",
    "plt.savefig(\"shaped_classifier_ROC.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529593337151719"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - metrics.roc_auc_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7783846885778357"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(labels_test, LL_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
