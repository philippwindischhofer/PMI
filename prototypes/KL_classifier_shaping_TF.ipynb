{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.mlab import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.distributions as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(n_samples):\n",
    "    data = []\n",
    "    labels = []\n",
    "    nuisances = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        sig_bkg = np.random.uniform(low = 0.0, high = 1.0, size = 1)\n",
    "        if sig_bkg > 0.5:\n",
    "            nuisance = np.random.uniform(low = 0.0, high = 2.0, size = 1)\n",
    "            data.append(np.random.multivariate_normal(mean = [0.0, nuisance], cov = np.array([[1, -0.5], [-0.5, 1]]), size = 1).flatten())\n",
    "            labels.append(1.0)\n",
    "        else:\n",
    "            nuisance = np.random.uniform(low = 0.0, high = 2.0, size = 1)\n",
    "            data.append(np.random.multivariate_normal(mean = [1.0, nuisance], cov = np.eye(2), size = 1).flatten())\n",
    "            labels.append(0.0)\n",
    "            \n",
    "        nuisances.append(nuisance)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    nuisances = np.array(nuisances)\n",
    "    \n",
    "    return data, labels, nuisances.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "data_train, labels_train, nuisances_train = prepare_data(num_samples)\n",
    "nuisances_train = np.expand_dims(nuisances_train, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8, \\\n",
    "                        allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "sess = tf.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch size for evaluation of mutual entropy\n",
    "MINE_batch_size = num_samples\n",
    "\n",
    "# batch size for the training of the encoder / classifier pair\n",
    "batch_size = 200\n",
    "\n",
    "bottleneck_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_in = tf.placeholder(tf.float32, [None, 2], name = 'data_in')\n",
    "nuisances_in = tf.placeholder(tf.float32, [None, 1], name = 'nuisances_in')\n",
    "labels_in = tf.placeholder(tf.int32, [None, ], name = 'labels_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier(classifier_input):\n",
    "    with tf.variable_scope(\"classifier\"):\n",
    "        lay = layers.relu(classifier_input, 20)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        lay = layers.relu(lay, 2)\n",
    "        outputs = layers.softmax(lay)\n",
    "        \n",
    "        these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"classifier\")\n",
    "\n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computes the KL divergence D_KL(P||Q) between the distributions of P and Q, \n",
    "# given an equal number of samples drawn from them\n",
    "def KL_network(data_P, data_Q, name):\n",
    "    with tf.variable_scope(name):  \n",
    "        data_combined = tf.concat([data_P, data_Q], axis = 0)\n",
    "        \n",
    "        lay = layers.relu(data_combined, 20)\n",
    "        lay = layers.relu(lay, 20)\n",
    "        outputs = layers.linear(lay, 1)\n",
    "        \n",
    "    these_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = name)\n",
    "    \n",
    "    return outputs, these_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KL_loss(KL_output, name):\n",
    "    with tf.variable_scope(name):\n",
    "        batch_size_dyn = tf.cast(tf.math.divide(tf.shape(KL_output)[0], 2), tf.int32)\n",
    "        \n",
    "        T_P = KL_output[:batch_size_dyn,:]\n",
    "        T_Q = KL_output[batch_size_dyn:,:]\n",
    "        \n",
    "        TF_loss = -(tf.reduce_mean(T_P, axis = 0) - tf.math.log(tf.reduce_mean(tf.math.exp(T_Q), axis = 0)))\n",
    "        \n",
    "        TF_loss = TF_loss[0]\n",
    "        \n",
    "    return TF_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model_params'):\n",
    "    low = tf.Variable(0.0, 'low')\n",
    "    high = tf.Variable(1.0, 'high')\n",
    "\n",
    "model_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'model_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ds.Uniform(low = low, high = high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_model = model.sample((50000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_output, classifier_vars = classifier(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_output_expanded = tf.expand_dims(classifier_output[:,0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KL_output, KL_vars = KL_network(classifier_output_expanded, samples_model, name = 'KL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KL_lossval = KL_loss(KL_output, 'KL_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_one_hot = tf.one_hot(labels_in, depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_loss = tf.losses.softmax_cross_entropy(onehot_labels = labels_one_hot, logits = classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KL_regularized_loss = classification_loss - KL_lossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_classifier = tf.train.AdamOptimizer(learning_rate = 0.0005, beta1 = 0.9, beta2 = 0.999).minimize(classification_loss, var_list = classifier_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_regularized_classifier = tf.train.AdamOptimizer(learning_rate = 0.0005, beta1 = 0.9, beta2 = 0.999).minimize(KL_regularized_loss, var_list = classifier_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_KL = tf.train.AdamOptimizer(learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999).minimize(KL_lossval, var_list = KL_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined training\n",
    "classification_loss_evolution = []\n",
    "MI_evolution = []\n",
    "number_batches = 200\n",
    "MINE_batches = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bkg = labels_train == 0\n",
    "bkg = data_train[train_bkg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL = 0.005061395466327667\n",
      "KL = 1.5067826509475708\n",
      "KL = 1.7006685733795166\n",
      "KL = 1.7273335456848145\n",
      "KL = 1.7815920114517212\n"
     ]
    }
   ],
   "source": [
    "# pre-train KL\n",
    "for batch in range(500):\n",
    "    inds = np.random.choice(len(bkg), 50000)\n",
    "    bkg_train = bkg[inds]\n",
    "    \n",
    "    sess.run(train_KL, feed_dict = {data_in: bkg_train})\n",
    "    \n",
    "    if not batch % 100:\n",
    "        cur_KL = -sess.run(KL_lossval, feed_dict = {data_in: bkg})\n",
    "        print(\"KL = {}\".format(cur_KL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL after pre-training = 1.911511778831482\n"
     ]
    }
   ],
   "source": [
    "cur_KL = -sess.run(KL_lossval, feed_dict = {data_in: bkg})\n",
    "print(\"KL after pre-training = {}\".format(cur_KL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "class_loss = 0.6947744488716125, KL = 1.918702483177185\n",
      "class_loss = 0.6653884649276733, KL = 1.067345142364502\n",
      "epoch 1\n",
      "class_loss = 0.6621788144111633, KL = 0.9554462432861328\n",
      "class_loss = 0.6605706214904785, KL = 0.873809814453125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    print(\"epoch {}\".format(epoch))\n",
    "    \n",
    "    for batch in range(number_batches):\n",
    "        # train classifier on sig + bkg\n",
    "        inds = np.random.choice(len(data_train), batch_size)\n",
    "        data_batch = data_train[inds]\n",
    "        labels_batch = labels_train[inds]\n",
    "        nuisances_batch = nuisances_train[inds]\n",
    "        sess.run(train_classifier, feed_dict = {data_in: data_batch, labels_in: labels_batch})\n",
    "        \n",
    "        # update KL\n",
    "        for i in range(20):\n",
    "            inds = np.random.choice(len(bkg), 50000)\n",
    "            bkg_train = bkg[inds]\n",
    "            sess.run(train_KL, feed_dict = {data_in: bkg_train})\n",
    "        \n",
    "        # train regularized classifier on bkg only\n",
    "        bkg = data_train[train_bkg]\n",
    "        labels_bkg = labels_train[train_bkg]\n",
    "        inds = np.random.choice(len(bkg), 50000)\n",
    "        bkg_train = bkg[inds]\n",
    "        labels_bkg_train = labels_bkg[inds]\n",
    "        sess.run(train_regularized_classifier, feed_dict = {data_in: bkg_train, labels_in: labels_bkg_train})\n",
    "        \n",
    "        if not batch % 100:\n",
    "            cur_KL = -sess.run(KL_lossval, feed_dict = {data_in: bkg})\n",
    "            class_loss = sess.run(classification_loss, feed_dict = {data_in: data_train, labels_in: labels_train})\n",
    "            print(\"class_loss = {}, KL = {}\".format(class_loss, cur_KL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = np.loadtxt(\"data_test.txt\")\n",
    "nuisances_test = np.loadtxt(\"nuisances_test.txt\")\n",
    "labels_test = np.loadtxt(\"labels_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = sess.run(classifier_output, feed_dict = {data_in: data_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.28263924, 0.71736073],\n",
       "       [0.2658787 , 0.73412126],\n",
       "       ...,\n",
       "       [0.42714542, 0.5728546 ],\n",
       "       [0.4402663 , 0.5597337 ],\n",
       "       [0.48735985, 0.5126401 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xi = np.linspace(-4, 4, 1000)\n",
    "yi = np.linspace(-4, 6, 1000)\n",
    "zi = griddata(data_test[:, 0], data_test[:, 1], pred[:, 0], xi, yi, interp = \"linear\")\n",
    "\n",
    "plt.contourf(xi, yi, zi, interp='linear', levels = 20)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hexbin(x = data_train[:, 0], y = data_train[:, 1], bins = 'log', gridsize = 50)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig = data_test[labels_test == 1]\n",
    "bkg = data_test[labels_test == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sig = sess.run(classifier_output, feed_dict = {data_in: sig})\n",
    "pred_bkg = sess.run(classifier_output, feed_dict = {data_in: bkg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([pred_sig[:,1], pred_bkg[:,1]], label = ['sig', 'bkg'], histtype = 'step', density = True, stacked = False, fill = False, bins = 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot ROC curves\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(labels_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(labels_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and load back the values of the (exact) ML estimator evaluated on them\n",
    "LL_pred = np.loadtxt(\"LL_evaluated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr_LL, tpr_LL, thresholds_LL = metrics.roc_curve(labels_test, LL_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(labels_test, LL_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot both of them into the same graph\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label = 'shaped classifier', c = 'red')\n",
    "ax.plot(fpr_LL, tpr_LL, label = 'analytic likelihood', c = 'black', ls = 'dashed')\n",
    "leg = ax.legend(loc = 'lower right')\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
